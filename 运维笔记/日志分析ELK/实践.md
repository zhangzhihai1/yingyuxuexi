# 1.ELFK实践

下载地址：https://www.elastic.co/cn/downloads/past-releases#elasticsearch

## 1.1资源初始化

| 节点 IP    | 主机名      | 节点服务                             | 推荐 CPU / 内存（测试环境） |
| ---------- | ----------- | ------------------------------------ | --------------------------- |
| 10.0.0.169 | es-node1    | Elasticsearch（master/data），Kibana | 1 核 / 2 GB                 |
| 10.0.0.170 | es-node2    | Elasticsearch（master/data）         | 1 核 / 1 GB                 |
| 10.0.0.171 | es-node3    | Elasticsearch（master/data）         | 1 核 / 1 GB                 |
| 10.0.0.172 | web-node1   | Web 服务，Filebeat                   | 1 核 / 512 MB               |
| 10.0.0.173 | web-node2   | Web 服务，Filebeat                   | 1 核 / 512 MB               |
| 10.0.0.174 | web-node3   | Web 服务，Filebeat                   | 1 核 / 512 MB               |
| 10.0.0.175 | kafka-node1 | Kafka（broker1）                     | 1 核 / 1 GB                 |
| 10.0.0.176 | kafka-node2 | Kafka（broker2）                     | 1 核 / 1 GB                 |
| 10.0.0.177 | kafka-node3 | Kafka（broker3）                     | 1 核 / 1 GB                 |
| 10.0.0.178 | logstash    | Logstash                             | 1 核 / 1 GB                 |
| 10.0.0.179 | ansible     | ansible                              | ansible                     |

### 1.1.1样板机环境初始化

```powershell
[root@bogon ~]# cat /etc/NetworkManager/system-connections/ens160.nmconnection 
[connection]
id=ens160
type=ethernet
autoconnect-priority=-999
interface-name=ens160
timestamp=1754998951

[ethernet]

[ipv4]
method=manual
address1=10.0.0.169/24,10.0.0.2
dns=10.0.0.2;

[ipv6]
addr-gen-mode=eui64
method=ignore

[proxy]

nmcli connection show
nmcli device ens160 up
```

环境初始化

```powershell
#!/bin/bash
# Rocky Linux 初始化优化脚本

set -euo pipefail  # 严格模式：遇错退出、未定义变量报错、管道错误中止
IFS=$'\n\t'

echo ">>> 切换 Rocky Linux 官方源到阿里云镜像..."
sudo sed -e 's|^mirrorlist=|#mirrorlist=|g' \
    -e 's|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g' \
    -i.bak \
    /etc/yum.repos.d/rocky-*.repo

echo ">>> 更新软件缓存..."
sudo dnf makecache -y

echo ">>> 安装常用工具..."
sudo dnf install -y epel-release \
    lrzsz wget vim tar coreutils tree bash-completion \
    net-tools mlocate yum-utils device-mapper-persistent-data lvm2

echo ">>> 关闭 SELinux..."
sudo sed -i 's/^SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config
sudo setenforce 0 || true  # 如果当前已是 permissive 会报错，这里忽略

echo ">>> 关闭防火墙..."
sudo systemctl disable --now firewalld
sudo systemctl mask firewalld

echo ">>> 关闭虚拟内存..."
sudo sed -i.bak '/swap/s/^/#/' /etc/fstab
swapoff -a

echo ">>> 启用 Bash 自动补全..."
if ! grep -q "bash_completion" ~/.bashrc; then
cat <<'EOF' >> ~/.bashrc
if [ -f /usr/share/bash-completion/bash_completion ]; then
    . /usr/share/bash-completion/bash_completion
fi
EOF
fi

echo ">>> 时间同步..."
cat <<EOF > /etc/chrony.conf
server time1.aliyun.com iburst
server time2.aliyun.com iburst
server time3.aliyun.com iburst
makestep 1.0 -1
EOF

echo ">>> 重新加载 bashrc..."
source ~/.bashrc

echo ">>> 主机名配置..."
cat >> /etc/hosts << EOF
10.0.0.169 es-node1
10.0.0.170 es-node2
10.0.0.171 es-node3
10.0.0.172 web-node1
10.0.0.173 web-node2
10.0.0.174 web-node3
10.0.0.175 kafka-node1
10.0.0.176 kafka-node2
10.0.0.177 kafka-node3
10.0.0.178 logstash
10.0.0.179 ansible
EOF

echo "系统初始化完成！"
```

### 1.1.2ansible安装配置

```powershell
dnf install -y ansible
ansible --version

免密登录脚本
#!/bin/bash

# 配置
PASSWORD="123456"
USER="root"  # 请替换为实际用户名

# 生成 SSH 密钥对（如果没有的话）
if [ ! -f ~/.ssh/id_rsa ]; then
    echo "生成 SSH 密钥对..."
    ssh-keygen -t rsa -b 2048 -N "" -f ~/.ssh/id_rsa
fi

# 将公钥复制到目标主机
for i in {169..179}
do
    echo "将公钥复制到 10.0.0.$i ..."
    sshpass -p "$PASSWORD" ssh-copy-id -o StrictHostKeyChecking=no -i ~/.ssh/id_rsa.pub "$USER@10.0.0.$i"
done

# 测试免密登录并执行命令（这里示例是查看主机名）
for i in {169..179}
do
    echo "连接到 10.0.0.$i 并执行命令..."
    sshpass -p "$PASSWORD" ssh -o StrictHostKeyChecking=no "$USER@10.0.0.$i" 'hostname'
done

echo "所有主机免密登录测试完成！"
```

## 1.2通过ansible部署所有的环境

```powershell
https://www.elastic.co/cn/support/matrix  兼容

https://www.elastic.co/cn/downloads/past-releases#elasticsearch

https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.17.5-linux-x86_64.tar.gz
https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.17.5-linux-x86_64.tar.gz
https://artifacts.elastic.co/downloads/kibana/kibana-7.17.5-linux-x86_64.tar.gz
https://artifacts.elastic.co/downloads/logstash/logstash-7.17.5-x86_64.rpm


kafka包下载
https://downloads.apache.org/kafka/3.9.0   只保留一部分版本
```

### 1.2.1elasticsearch

```powershell
候选 master 保持集群元数据同步、监控 Active Master，并随时准备接管。只是它们不主动做“集群状态变更”的决策而已。
Elasticsearch 不允许 主分片和它的副本放在同一节点

master负责
集群管理
选举并成为集群的唯一主节点（Active Master）
维护集群状态（Cluster State）

元数据管理
管理索引的创建、删除、映射（mapping）
管理分片（shard）的分配、迁移、复制

故障检测与恢复
检测节点是否掉线
在节点宕机时重新分配分片
不参与实际数据存储和查询
Master 节点一般不存储业务数据，不执行搜索聚合（除非同时被配置成 data 节点）

Data 节点（数据节点）
主要职责：
存储数据分片（Shard）
Primary Shard（主分片）
Replica Shard（副本分片）
执行数据操作
文档的增删改（CRUD）
查询（Search）与聚合（Aggregation）
响应客户端请求
参与分布式查询，返回部分结果给协调节点（coordinating node）

路由节点的作用
接收客户端请求：
你发的 HTTP/REST 请求（搜索、索引等）可能打到任意一个节点。
如果这个节点不是存储数据的节点，它就会充当路由/协调节点。
确定目标分片：
对于写入请求（索引文档），路由节点会根据文档 ID + 路由算法（hash(id) % number_of_primary_shards）算出目标主分片位置，并把请求转发过去。
对于查询请求，路由节点会把查询发到所有相关分片（主分片 + 副本分片），再收集结果。
聚合和排序：
每个分片返回自己的结果集，路由节点负责把它们合并、去重、排序、分页，再返回给客户端。
负载均衡：
路由节点可以分担客户端与数据节点之间的压力，避免数据节点被直接打爆。
```

遇到的问题

```powershell
目录权限应该给服务用户
重启之后虚拟机文件系统变成了只读mount | grep 'on / '
解决：sudo mount -o remount,rw /
```

端口起不来

```powershell
内存给的不够512MB太低，给1024MB
xms必须等于xmx

#如果是做过集群的节点转换为单节点必须清空数据，因为cluster state不允许改变
systemctl stop elasticsearch
rm -rf /opt/elasticsearch/data/*
./bin/elasticsearch

# 编辑 sysctl 配置
echo "vm.max_map_count=262144" >> /etc/sysctl.conf
sysctl -p
```

操作

```powershell
#增删改查文档
https://www.elastic.co/docs/reference/query-languages/querydsl
#查看支持的指令
curl http://127.0.0.1:9200/_cat

#查看es集群状态
curl http://127.0.0.1:9200/_cat/health
curl 'http://127.0.0.1:9200/_cat/health?v'

#查看集群分健康性,获取到的是一个json格式的返回值，那就可以通过python等工具对其中的信息进行分析，，，做脚本监控
#注意: status 字段为green才是正常状态
curl http://127.0.0.1:9200/_cluster/health?pretty=true

#查看所有的节点信息
curl 'http://127.0.0.1:9200/_cat/nodes?v'

#列出所有的索引 以及每个索引的相关信息
curl 'http://127.0.0.1:9200/_cat/indices?v'
```

可视化插件

```powershell
head
cerebro插件
https://github.com/lmenezes/cerebro
```

### 1.2.2 kibana

### 1.2.3logstash

### 1.2.4.kafka

### 1.2.5.filebeat

```powershell
filebeat: 收集日志文件数据。最常用的工具
packetbeat: 用于收集网络数据。一般用zabbix实现此功能
metricbeat: 从OS和服务收集指标数据，比如系统运行状态、CPU 内存利用率等。
winlogbeat: 从windows平台日志收集工具。
heartbeat: 定时探测服务是否可用。支持ICMP、TCP 和 HTTP，也支持TLS、身份验证和代理
auditbeat: 收集审计日志
Functionbeat: 使用无服务器基础架构提供云数据。面向云端数据的无服务器采集器，处理云数据

只管filebeat，其他beats我们不管
```



