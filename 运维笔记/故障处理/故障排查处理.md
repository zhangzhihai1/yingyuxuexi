[TOC]

# 故障排查处理

## 1.应用运维相关故障排查

### 1.1运行环境相关

#### 1.1.1链接库（依赖库）问题分析

链接库问题在软件开发过程中是相当常见的，尤其是在涉及多个模块、第三方库或跨平台开发时。这些问题可能源于多种原因，下面我将总结一些主要的原因：

1. **库文件缺失**

   - **描述**：编译或运行时找不到所需的库文件。
   - **原因**：
     - 库文件未安装。
     - 库文件路径配置不正确。
     - 环境变量（如 `LD_LIBRARY_PATH` 在 Linux 上）没有包含库文件所在的目录。

2. **版本不匹配**

   - **描述**：程序依赖的库版本与实际使用的库版本不一致。
   - **原因**：
     - 开发环境和生产环境中的库版本不同。
     - 多个依赖库之间存在版本冲突。
     - 使用了过时或预发布版本的库，导致API变化。

3. **符号解析错误**

   - **描述**：链接器无法找到函数或变量的定义。
   - **原因**：
     - 函数或变量声明但未定义。
     - 链接顺序不对，某些库应该在其他库之前链接。
     - 静态库和动态库混用不当。

4. **ABI（应用程序二进制接口）不兼容**

   - **描述**：即使源代码兼容，由于不同的编译器选项或其他因素，生成的二进制文件可能不兼容。
   - **原因**：
     - 编译器版本差异。
     - 编译选项（如优化级别、标准库版本等）不同。
     - 不同操作系统之间的ABI差异。

5. **依赖关系管理不当**

   - **描述**：项目直接或间接依赖的库之间存在循环依赖或缺少必要的依赖。
   - **原因**：
     - 使用包管理工具（如 `npm`, `pip`, `maven`）时，依赖树中存在冲突。
     - 手动管理依赖时遗漏了某些必需的库。

6. **平台特定问题**

   - **描述**：在某个平台上工作正常的代码，在另一个平台上出现问题。
   - **原因**：
     - 操作系统级别的差异（如 Windows 和 Linux 的文件系统、线程模型等）。
     - 硬件架构差异（如 x86 和 ARM 架构）。
     - 动态链接库的查找机制不同。

7. **符号重复定义**（基本不可能）

   - **描述**：同一个符号（函数或变量）被多次定义。
   - **原因**：
     - 同一个库被多次引入。
     - 全局命名空间污染，多个库定义了相同名称的符号。

8. **编译与链接选项错误**

   - **描述**：由于编译或链接时使用的选项不当导致的问题。
   - **原因**：
     - 缺少 `-l` 选项指定需要链接的库。
     - 使用了不正确的 `-L` 路径来查找库。
     - 编译器和链接器使用的标准库版本不一致。

9. **静态与动态库的选择**

   - **描述**：选择静态库还是动态库影响最终可执行文件的行为。
   - **原因**：
     - 动态库在运行时加载失败（如找不到 `.so` 文件）。
     - 静态库可能导致可执行文件过大，并且难以更新。

10. **权限问题**

    - **描述**：访问库文件时权限不足。
    - **原因**：
      - 当前用户对库文件或其所在目录没有读取权限。
      - 运行时需要写入临时文件但无相应权限。

解决策略

- **检查并修复路径设置**：确保所有依赖的库都在正确的路径下，并且这些路径已添加到相应的环境变量中。
- **使用包管理工具**：利用如 `CMake`, `Pip`, `Maven` 等工具自动解决依赖关系。
- **统一构建环境**：尽量保持开发和生产环境的一致性，包括操作系统版本、编译器版本等。
- **详细阅读文档**：了解每个库的具体要求及其与其他库的关系。
- **调试工具**：使用 `ldd` (Linux), `Dependency Walker` (Windows) 等工具分析可执行文件的依赖情况。

通过理解上述原因，可以更有针对性地排查和解决链接库相关的问题。如果你遇到具体的链接库问题，欢迎提供更多信息，我可以进一步帮助你分析和解决。 😊

##### 1.1.1.1示例

### 1.2java微服务生产环境故障排查

#### 1.2.1cpu飙高

Arthas 是由阿里巴巴开源的一款强大的 **Java 线上诊断工具**，专门用于在 **不中断服务、不重启进程的前提下**，对正在运行中的 Java 应用进行问题排查。

------

✅ Arthas 是什么？

> Arthas 是 JVM 诊断的“瑞士军刀”，它可以 attach 到运行中的 Java 应用，动态分析方法调用、参数、返回值、耗时、线程、异常、GC、类加载等信息。

------

🔧 Arthas 能做什么（常见用途）：

| 类别         | 功能                           | 命令                      |
| ------------ | ------------------------------ | ------------------------- |
| 方法调用分析 | 查看某个方法的入参、返回、异常 | `watch`、`trace`、`tt`    |
| 性能热点分析 | 查看最耗 CPU 的线程、阻塞线程  | `top`, `thread`           |
| 反编译源码   | 查看类的方法签名和源码         | `jad`、`mc`               |
| 动态代理     | 修改 class 行为（无需重启）    | `retransform`, `monitor`  |
| 类加载分析   | 判断类由哪个 jar 加载          | `sc`, `sm`, `classloader` |

------

✅ 快速案例：高 CPU 现场排查

🧩 场景：

你发现微服务 CPU 突然飙高，怀疑是某个方法卡住或死循环。

------

📦 步骤 1：连接目标进程

```bash
./as.sh   # 自动列出 JVM 进程（或者用 ./arthas-boot.jar ）
```

选择你要分析的 Java 应用编号即可连接。

------

📦 步骤 2：查看最耗 CPU 的线程

```bash
thread -n 5
```

输出示例：

```
"http-nio-8080-exec-10" Id=47 cpuUsage=83%
    at com.example.service.OrderService.queryOrders(OrderService.java:45)
```

发现某个线程 CPU 占用极高，调用 `OrderService.queryOrders()`。

------

📦 步骤 3：查看调用堆栈（trace）

```bash
trace com.example.service.OrderService queryOrders
```

输出：

```
|---com.example.service.OrderService.queryOrders() # took 2031ms
    |---com.example.dao.OrderDao.findAll() # took 2000ms
        |---com.mysql.jdbc.Driver.executeQuery() # took 1998ms
```

结论：**数据库查询耗时严重，可能索引失效或传参异常。**

------

📦 步骤 4：看方法参数和返回值（watch）

```bash
watch com.example.service.OrderService queryOrders "{params, returnObj}" -x 3
```

输出示例：

```json
params[0]: null
returnObj: []
```

发现你传入了 `null` 参数，导致执行全表扫描。

------

✅ 总结一句话（面试 or 汇报）

> “Arthas 可以在不停服务的情况下 attach 到 Java 进程，实时查看方法调用、线程状态、类加载等信息，我曾用它 trace 出 CPU 飙高是因为某方法传参错误导致数据库全表扫描。”

------

🧠 常用命令清单（建议收藏）

| 命令                                         | 功能                   |
| -------------------------------------------- | ---------------------- |
| `thread -n 5`                                | 查看最耗 CPU 的线程    |
| `trace <class> <method>`                     | 追踪方法调用路径及耗时 |
| `watch <class> <method> {params, returnObj}` | 监控方法入参/返回值    |
| `jad <class>`                                | 反编译类源码           |
| `sc -d <class>`                              | 查看类信息及来源 JAR   |
| `tt`                                         | 查看方法执行记录并回放 |

------

需要我给你写一份 Spring Boot 微服务 + Arthas 使用手册（包含部署、定位慢查询、线程死锁等场景）吗？可以更系统地掌握它。

## 2.网络相关故障

### 2.1仅主机与桥接

在vmare虚拟网络设置中将一个网段设置为了仅主机模式，在虚拟机中加入桥接网卡，设置为该网段后实际上是仅主机，而不是桥接

## 2.2网络不通

DNS

ip route

## 3.硬盘相关故障

### 3.1移除硬盘后进入紧急模式

删除/etc/fstab挂载

为什么新增硬盘重启会导致重启后进入安装虚拟机界面？

**虚拟机引导顺序错误**

- 重启虚拟机，在启动界面狂按 `F2` 或 `ESC` 进入 ‌**BIOS/UEFI 设置**‌。
- 在 ‌**Boot**‌ 标签页中，将 `Hard Drive`（或具体虚拟硬盘）通过 `+/-` 键移至首位7。
- 保存设置（通常按 `F10`）并退出



# 监控与改善

## 1.错误日志监控告警

### 1.1java业务代码抛出异常

#### 无法分辨有效的错误日志导致无效告警过多

是非常典型的 **日志爆炸（log flooding）** 问题。它不仅会掩盖真正的问题，还可能导致日志系统资源浪费、排查效率下降。

---

✅ 一、为什么会“异常太多”？

1. **过度使用异常作为流程控制**

- 滥用 `try-catch` 包裹所有操作；
- 把业务逻辑判断也写成异常处理；
- 导致频繁抛出/捕获异常；

```java
try {
    int result = Integer.parseInt(str); // 字符串可能为空或非法
} catch (NumberFormatException e) {
    // 处理逻辑直接在这里写了，而不是提前判断
}
```

✅ 改进建议：对于可预见的情况，应优先使用条件判断，而不是依赖异常机制。

---

2. **未分类处理异常**

- 所有异常都统一打印 + 抛出；
- 没有区分“业务异常”和“系统异常”；
- 导致日志中大量重复无意义信息；

---

3. **未做异常级别分级**

- 所有异常都标记为 ERROR；
- 没有 INFO / WARN / ERROR 分级；
- 日志平台无法过滤关键信息；

---

4. **异常链混乱**

- 多层 try-catch，层层包装；
- 异常堆栈过长，难以定位原始原因；

---

✅ 二、如何解决？—— 有效日志管理策略

🎯 目标：

> 让日志清晰、可控、可追踪，只记录**必要的异常信息**，屏蔽“噪音”。

---

✅ 1. **明确异常类型，分类处理**

| 类型       | 示例                              | 是否需要告警 | 是否需要日志            |
| ---------- | --------------------------------- | ------------ | ----------------------- |
| 系统异常   | NullPointerException, IOException | ✅ 是         | ✅ 是                    |
| 业务异常   | 参数校验失败、余额不足等          | ❌ 否         | ✅ 是（但可降级为 warn） |
| 可预期异常 | 接口调用失败、网络超时等          | ⚠️ 视情况而定 | ✅ 是                    |

✅ 建议：
- 自定义异常类：如 `BusinessException`, `ThirdPartyException`；
- 使用日志级别区分对待；
- 配置日志框架输出不同级别的日志到不同文件；

---

✅ 2. **合理使用日志级别**

| 级别  | 用途     | 推荐场景                 |
| ----- | -------- | ------------------------ |
| DEBUG | 调试信息 | 开发阶段、排查 bug       |
| INFO  | 流程日志 | 正常流程中的关键点       |
| WARN  | 预警信息 | 可容忍但需关注的异常     |
| ERROR | 错误信息 | 不可恢复的异常、系统错误 |

示例：

```java
try {
    // ...
} catch (BusinessException e) {
    logger.warn("用户输入错误: {}", e.getMessage()); // 不影响系统运行
}

try {
    // ...
} catch (IOException e) {
    logger.error("系统IO异常，请立即检查！", e);
}
```

---

✅ 3. **避免日志冗余（防刷保护）**

✅ 方式一：限制相同内容的日志频率

- 比如同一个异常在 5 分钟内不再重复打印；
- 可以使用缓存记录时间戳或 hash 值；

✅ 方式二：使用日志框架插件

- 如 Logback 的 `TurboFilter` 或 `SiftingAppender`；
- 按照异常类型、线程名、包名等进行分流；

---

✅ 4. **引入上下文信息（MDC）**

使用 `MDC（Mapped Diagnostic Context）` 添加请求 ID、用户 ID、IP 等上下文信息，便于日志追踪。

```java
MDC.put("requestId", UUID.randomUUID().toString());
logger.info("开始处理请求");
// 输出格式可以是：
// [requestId=xxx] 用户登录失败：用户名或密码错误
```

---

✅ 5. **使用 AOP 统一处理异常（推荐）**

如果你使用 Spring Boot，可以通过全局异常处理器统一处理异常，集中决定是否记录日志、发送告警、返回错误码等。

```java
@RestControllerAdvice
public class GlobalExceptionHandler {

    @ExceptionHandler(BusinessException.class)
    public ResponseEntity<String> handleBusinessException(BusinessException ex) {
        // 仅记录 warn 日志，不报警
        log.warn("业务异常: {}", ex.getMessage());
        return ResponseEntity.badRequest().body(ex.getMessage());
    }

    @ExceptionHandler(Exception.class)
    public ResponseEntity<String> handleUnexpectedException(Exception ex) {
        // 记录 error 日志，并触发钉钉告警
        log.error("系统异常: ", ex);
        DingTalkUtils.sendTextMessageAsync("【系统异常】" + ex.getMessage(), null, false);
        return ResponseEntity.status(500).body("系统内部错误");
    }
}
```

---

✅ 6. **使用日志聚合平台（ELK / Graylog）**

将日志集中管理，通过 Kibana / Grafana 过滤、统计、可视化：

- 设置日志等级过滤器；
- 对特定异常设置告警规则；
- 查看异常趋势图、分布图；
- 快速定位高频异常源头；

---

✅ 三、总结一句话：

> “异常多”不是问题，“异常杂乱无章”才是问题。通过 **分类处理、分级记录、上下文增强、异步通知、日志聚合** 等手段，可以让你的日志变得清晰、易读、有价值。

---

📌 最后建议 —— 日志设计最佳实践（Checklist）

| 操作                    | 是否推荐     |
| ----------------------- | ------------ |
| 异常用于真正的错误场景  | ✅ 是         |
| 用异常代替 if 判断      | ❌ 否         |
| 全部异常都打 ERROR 日志 | ❌ 否         |
| 每个异常都打印堆栈      | ⚠️ 视情况而定 |
| 使用 MDC 增强日志可读性 | ✅ 是         |
| 使用 AOP 统一处理异常   | ✅ 是         |
| 异步发送告警通知        | ✅ 是         |
| 使用日志平台分析日志    | ✅ 是         |

